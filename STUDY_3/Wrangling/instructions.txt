:: /session_files raw exports (json) from each session to be downloaded to
:: /db_scripts scripts to extract (processed) data from local db to file for analysis import
:: /data_files processed data files for import with R analysis

STEP ONE: EXPORT DATA FROM DB SERVER TO FILE
---
//for each session, export the records into a json file for the session from the server
mongoexport -h [connectionstring] -d [dbname] -c [tablename] -u [username] -p [password] --out [filename]
mongoexport -h ds259325.mlab.com:59325 -d 2ypdb-s3-beh -c entries -u expadmin -p thirdyear --out alfa-bravo-charlie.json


STEP TWO: IMPORT DATA FROM SESSION FILES TO LOCAL DB
---
//start local database (in any directory) run
mongod
//import the previously exported file into the local DB for analysis
mongoimport -d [DBNAME] -c [SESSIONNAME] --file [filename.json]
mongoimport -d STUDY3 -c alfa-bravo-charlie --file alfa-bravo-charlie.json

STEP THREE: EXTRACT DATA FROM LOCAL db
// start (visual) DB GUI (roboMongo)
// access relevant data analysis script (ie. flatten.js)
// convert final extracted records from .json to .csv using https://json-csv.com/


levels of analysis
:: participant
:: item
:: mouse

-------------------------------------------------------------





STEP FOUR: manually construct master spss / R data sets
> in each _participants.xls file created, manually split demographics fields into separate columns by ','delimiter
> create _min (or _m) translations for each time field (recorded in miliseconds)
